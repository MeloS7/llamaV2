{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/9130/.cache/huggingface/datasets/json/default-c0867ada11e1561a/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "file_path = \"../data/to_annotate_150_cleaned.json\"\n",
    "dataset = load_dataset(\"json\", data_files=file_path, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef4e0de67e34951a2dce2b5db576690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "\n",
    "# Version 2-7b\n",
    "# base_model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "# Version 2-13b-chat\n",
    "base_model_name = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "device_map = {\"\": 0}\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device_map,\n",
    "    trust_remote_code=True,\n",
    "    use_auth_token=True\n",
    ")\n",
    "\n",
    "base_model.config.use_cache = False\n",
    "\n",
    "# More info: https://github.com/huggingface/transformers/pull/24906\n",
    "base_model.config.pretraining_tp = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='meta-llama/Llama-2-13b-chat-hf', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False), 'pad_token': '</s>'}, clean_up_tokenization_spaces=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'f4acjs9',\n",
       " 'body_cleaned': 'as a federal leo , the very idea of confiscating guns is laughable . i swore an oath to the constitution , not to beto or any other politician .',\n",
       " 'User label': '',\n",
       " 'author': 'MDeXY',\n",
       " 'subreddit': 'progun',\n",
       " 'predicted_community': 0,\n",
       " 'score': 454,\n",
       " 'created_utc': 1571492410}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Custom Dataset and Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "# Define examples\n",
    "examples = [\n",
    "    {\n",
    "        \"instruction\": \"<<SYS>>\\nYou are a sentence sentiment polarity classification assistant about gun control. And here are definitions of labels: \\\n",
    "Support Gun: Explicitly opposes gun ownership or is in favor of legal policies such as banning guns and confiscating personal guns. \\\n",
    "Anti Gun: Explicitly in favor of individual gun ownership, or against gun bans and gun confiscation. \\\n",
    "Neutral: The statement is centered around the debate on gun control, but there is no clear opinion expressed. \\\n",
    "Not Relevant: Don't have any obvious relationship to guns. \\\n",
    "Not Sure: The sentence statements are describing gun support for owning / banning guns, but due to a lack of relevant context, or some other reason, we can sense the emotional inclination, but not the specific opinion or polarized aspect. \\\n",
    "And the sentences are considered as polarized if they are or about antagonizing statements / hostility / belittling / animosity: 'us vs them',  inter-group antagonism, radicalization, conflictive confrontation, and so on. \\\n",
    "the sentences are considered as non-polarized if they are or aboutc onstructive civic conversation, bring together to a common ground, peaceful dialogue, and so on. \\\n",
    "\\n<<SYS>>\\n\\nPlease classify the sentiment polarity of the following sentence about gun support into one of the following categories: \\\n",
    "'Support Gun Polarized', 'Support Gun non-Polarized', 'Neutral', 'Anti Gun Polarized', 'Anti Gun non-Polarized', 'Not relevant' or 'Not Sure':\",\n",
    "        \"sentence\": \"as a federal leo , the very idea of confiscating guns is laughable . i swore an oath to the constitution , not to beto or any other politician .\",\n",
    "        \"label\": \"Support Gun Polarized\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Please classify the sentiment polarity of the following sentence about gun support into one of the following categories: \\\n",
    "'Support Gun Polarized', 'Support Gun non-Polarized', 'Neutral', 'Anti Gun Polarized', 'Anti Gun non-Polarized', 'Not relevant' or 'Not Sure':\",\n",
    "        \"sentence\": \"we must ban this horrible weapon of war\",\n",
    "        \"label\": \"Anti Gun Polarized\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Please classify the sentiment polarity of the following sentence about gun support into one of the following categories: \\\n",
    "'Support Gun Polarized', 'Support Gun non-Polarized', 'Neutral', 'Anti Gun Polarized', 'Anti Gun non-Polarized', 'Not relevant' or 'Not Sure':\",\n",
    "        \"sentence\": \"this is also why i love hickok45 . he 's just an all-around good guy . one of the best representatives out there for the pro-2a community .\",\n",
    "        \"label\": \"Support Gun Non-Polarized\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Please classify the sentiment polarity of the following sentence about gun support into one of the following categories: \\\n",
    "'Support Gun Polarized', 'Support Gun non-Polarized', 'Neutral', 'Anti Gun Polarized', 'Anti Gun non-Polarized', 'Not relevant' or 'Not Sure':\",\n",
    "        \"sentence\": \"repeal the 2nd amendment make real national laws , strictly enforced .\",\n",
    "        \"label\": \"Anti Gun Non-Polarized\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Please classify the sentiment polarity of the following sentence about gun support into one of the following categories: \\\n",
    "'Support Gun Polarized', 'Support Gun non-Polarized', 'Neutral', 'Anti Gun Polarized', 'Anti Gun non-Polarized', 'Not relevant' or 'Not Sure':\",\n",
    "        \"sentence\": \"when seconds matter , the police are only minutes away ...\",\n",
    "        \"label\": \"Not Sure\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Please classify the sentiment polarity of the following sentence about gun support into one of the following categories: \\\n",
    "'Support Gun Polarized', 'Support Gun non-Polarized', 'Neutral', 'Anti Gun Polarized', 'Anti Gun non-Polarized', 'Not relevant' or 'Not Sure':\",\n",
    "        \"sentence\": \"i 'm convinced those two issues inspire most of the 5 % of the population that votes libertarian .\",\n",
    "        \"label\": \"Neutral\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Please classify the sentiment polarity of the following sentence about gun support into one of the following categories: \\\n",
    "'Support Gun Polarized', 'Support Gun non-Polarized', 'Neutral', 'Anti Gun Polarized', 'Anti Gun non-Polarized', 'Not relevant' or 'Not Sure':\",\n",
    "        \"sentence\": \"for good reason . god she sucked so much\",\n",
    "        \"label\": \"Not Relevant\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define example prompt and few-shot prompt\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"instruction\", \"sentence\", \"label\"], \n",
    "    template=\"<s><INST> {instruction}\\nSentence: {sentence}\\nSentiment Polarity: </INST> {label} </s>\",\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples, \n",
    "    example_prompt=example_prompt, \n",
    "    suffix=\"<s><INST> Please classify the sentiment polarity of the following sentence about gun support into one of the following categories: \\\n",
    "'Support Gun Polarized', 'Support Gun non-Polarized', 'Neutral', 'Anti Gun Polarized', 'Anti Gun non-Polarized', 'Not relevant' or 'Not Sure':\\nSentence: {sentence}\\nSentiment Polarity: </INST>\",\n",
    "    # suffix=\"<s><INST> Classify the sentiment of the following text only into these two categories :'positive' or 'negative':\\nSentence: {sentence}\\nSentiment: </INST>\", \n",
    "    input_variables=[\"sentence\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><INST> <<SYS>>\n",
      "You are a sentence sentiment polarity classification assistant about gun control. And here are definitions of labels: Support Gun: Explicitly opposes gun ownership or is in favor of legal policies such as banning guns and confiscating personal guns. Anti Gun: Explicitly in favor of individual gun ownership, or against gun bans and gun confiscation. Neutral: The statement is centered around the debate on gun control, but there is no clear opinion expressed. Not Relevant: Don't have any obvious relationship to guns. Not Sure: The sentence statements are describing gun support for owning / banning guns, but due to a lack of relevant context, or some other reason, we can sense the emotional inclination, but not the specific opinion or polarized aspect. And the sentences are considered as polarized if they are or about antagonizing statements / hostility / belittling / animosity: 'us vs them',  inter-group antagonism, radicalization, conflictive confrontation, and so on. the sentences are considered as non-polarized if they are or aboutc onstructive civic conversation, bring together to a common ground, peaceful dialogue, and so on. \n",
      "<<SYS>>\n",
      "\n",
      "Please classify the sentiment polarity of the following sentence about gun support into one of the following categories: 'Support Gun Polarized', 'Support Gun non-Polarized', 'Neutral', 'Anti Gun Polarized', 'Anti Gun non-Polarized', 'Not relevant' or 'Not Sure':\n",
      "Sentence: as a federal leo , the very idea of confiscating guns is laughable . i swore an oath to the constitution , not to beto or any other politician .\n",
      "Sentiment Polarity: </INST> Support Gun Polarized </s>\n",
      "\n",
      "<s><INST> Please classify the sentiment polarity of the following sentence about gun support into one of the following categories: 'Support Gun Polarized', 'Support Gun non-Polarized', 'Neutral', 'Anti Gun Polarized', 'Anti Gun non-Polarized', 'Not relevant' or 'Not Sure':\n",
      "Sentence: we must ban this horrible weapon of war\n",
      "Sentiment Polarity: </INST> Anti Gun Polarized </s>\n",
      "\n",
      "<s><INST> Please classify the sentiment polarity of the following sentence about gun support into one of the following categories: 'Support Gun Polarized', 'Support Gun non-Polarized', 'Neutral', 'Anti Gun Polarized', 'Anti Gun non-Polarized', 'Not relevant' or 'Not Sure':\n",
      "Sentence: this is also why i love hickok45 . he 's just an all-around good guy . one of the best representatives out there for the pro-2a community .\n",
      "Sentiment Polarity: </INST> Support Gun Non-Polarized </s>\n",
      "\n",
      "<s><INST> Please classify the sentiment polarity of the following sentence about gun support into one of the following categories: 'Support Gun Polarized', 'Support Gun non-Polarized', 'Neutral', 'Anti Gun Polarized', 'Anti Gun non-Polarized', 'Not relevant' or 'Not Sure':\n",
      "Sentence: repeal the 2nd amendment make real national laws , strictly enforced .\n",
      "Sentiment Polarity: </INST> Anti Gun Non-Polarized </s>\n",
      "\n",
      "<s><INST> Please classify the sentiment polarity of the following sentence about gun support into one of the following categories: 'Support Gun Polarized', 'Support Gun non-Polarized', 'Neutral', 'Anti Gun Polarized', 'Anti Gun non-Polarized', 'Not relevant' or 'Not Sure':\n",
      "Sentence: when seconds matter , the police are only minutes away ...\n",
      "Sentiment Polarity: </INST> Not Sure </s>\n",
      "\n",
      "<s><INST> Please classify the sentiment polarity of the following sentence about gun support into one of the following categories: 'Support Gun Polarized', 'Support Gun non-Polarized', 'Neutral', 'Anti Gun Polarized', 'Anti Gun non-Polarized', 'Not relevant' or 'Not Sure':\n",
      "Sentence: i 'm convinced those two issues inspire most of the 5 % of the population that votes libertarian .\n",
      "Sentiment Polarity: </INST> Neutral </s>\n",
      "\n",
      "<s><INST> Please classify the sentiment polarity of the following sentence about gun support into one of the following categories: 'Support Gun Polarized', 'Support Gun non-Polarized', 'Neutral', 'Anti Gun Polarized', 'Anti Gun non-Polarized', 'Not relevant' or 'Not Sure':\n",
      "Sentence: for good reason . god she sucked so much\n",
      "Sentiment Polarity: </INST> Not Relevant </s>\n",
      "\n",
      "<s><INST> Please classify the sentiment polarity of the following sentence about gun support into one of the following categories: 'Support Gun Polarized', 'Support Gun non-Polarized', 'Neutral', 'Anti Gun Polarized', 'Anti Gun non-Polarized', 'Not relevant' or 'Not Sure':\n",
      "Sentence: I am so happy!\n",
      "Sentiment Polarity: </INST>\n"
     ]
    }
   ],
   "source": [
    "sent2test = \"I am so happy!\"\n",
    "prompt2test = prompt.format(sentence=sent2test)\n",
    "print(prompt2test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ChatDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, prompt):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.prompt = prompt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        val = self.dataset[idx]\n",
    "        sentence = val['body_cleaned']\n",
    "        text = self.prompt.format(sentence=sentence)\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "        \n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [item['input_ids'].tolist() for item in batch]\n",
    "    attention_mask = [item['attention_mask'].tolist() for item in batch]\n",
    "\n",
    "    # Left Padding\n",
    "    max_length = max([len(item) for item in input_ids])\n",
    "    input_ids = [[0]*(max_length - len(item)) + item for item in input_ids]\n",
    "    attention_mask = [[0]*(max_length - len(item)) + item for item in attention_mask]\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def inference(dataset, prompt, batch_size=8):\n",
    "    to_annotate_dataset = copy.deepcopy(dataset)\n",
    "    to_annotate_dataset = to_annotate_dataset.remove_columns([\"User label\"])\n",
    "\n",
    "    chatDataset = ChatDataset(dataset, tokenizer, prompt)\n",
    "    data_loader = DataLoader(chatDataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    invalid_label = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i, batch in enumerate(tqdm(data_loader)):\n",
    "        # Move batch to GPU\n",
    "        input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "        attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "\n",
    "        # Generate for the entire batch\n",
    "        outputs = base_model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=512,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "        # Decode the generated text and labels\n",
    "        outputs_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        \n",
    "        # Evaluate the generated text\n",
    "        for idx in range(len(outputs_text)):\n",
    "            # Extract the last sentence\n",
    "            selected_sentiment = outputs_text[idx].split(\"\\n\")[-1].lower()\n",
    "            # Remove the prompt\n",
    "            selected_sentiment = selected_sentiment.split(\"</inst> \")[-1]\n",
    "\n",
    "            if selected_sentiment not in ['support gun polarized', 'support gun non-polarized', 'neutral', 'anti gun non-polarized', 'anti gun polarized', 'not sure', 'not relevant']:\n",
    "                invalid_label.append(selected_sentiment)\n",
    "            \n",
    "            all_labels.append(selected_sentiment)\n",
    "            # to_annotate_dataset[i * batch_size + idx][\"User label\"] = selected_sentiment\n",
    "    \n",
    "    # Add labels to the dataset\n",
    "    to_annotate_dataset = to_annotate_dataset.add_column(\"User label\", all_labels)\n",
    "\n",
    "    return to_annotate_dataset, invalid_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:51<00:00,  5.89s/it]\n"
     ]
    }
   ],
   "source": [
    "annotated_dataset, invalid_label = inference(dataset, prompt, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'body_cleaned', 'author', 'subreddit', 'predicted_community', 'score', 'created_utc', 'User label'],\n",
       "    num_rows: 150\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'dwx41ns',\n",
       " 'body_cleaned': 'meanwhile in england , an old man is being charged with murder after he killed one of the men breaking into his home',\n",
       " 'author': 'qhsBh',\n",
       " 'subreddit': 'progun',\n",
       " 'predicted_community': 0,\n",
       " 'score': 339,\n",
       " 'created_utc': 1523030793,\n",
       " 'User label': 'support gun polarized'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_dataset[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save annotated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8060aa56c674707918ff4f4d7a7b13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "44907"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_dataset.to_json('../data/annotated_data_llama2_v2_context.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
